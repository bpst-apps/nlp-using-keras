{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aEgYD7i6zVH"
   },
   "source": [
    "# Sequence to sequence learning for performing number addition\n",
    "\n",
    "**Description:** A model that learns to add strings of numbers, e.g. \"535+61\" -> \"596\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0C1Y_3Ri6zVM"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we train a model to learn to add two numbers, provided as strings.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- Input: \"535+61\"\n",
    "- Output: \"596\"\n",
    "\n",
    "Input may optionally be reversed, which was shown to increase performance in many tasks\n",
    " in: [Learning to Execute](http://arxiv.org/abs/1410.4615) and\n",
    "[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf).\n",
    "\n",
    "Theoretically, sequence order inversion introduces shorter term dependencies between\n",
    " source and target for this problem.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "For two digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZJ6LJz76zVN"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LN4vafH_6zVN"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQA_RYLX6zVO"
   },
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4Pt5ccIM6zVO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Q05sG646zVP"
   },
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vbcCnB3Z6zVQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thaku\\AppData\\Local\\Temp\\ipykernel_15784\\1046822725.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\thaku\\AppData\\Local\\Temp\\ipykernel_15784\\1046822725.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fY1kmbP6zVR"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZA7ANS7p6zVR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4, 12)             1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKExhIxQ6zVS"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WQvGgBWe6zVS",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 20s 7ms/step - loss: 1.7527 - accuracy: 0.3584 - val_loss: 1.5439 - val_accuracy: 0.4241\n",
      "1/1 [==============================] - 1s 517ms/step\n",
      "Q 392+46  T 438  â˜’ 310 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 900+56  T 956  â˜’ 903 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 301+78  T 379  â˜’ 331 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 957+532 T 1489 â˜’ 1337\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 0+425   T 425  â˜’ 530 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 9+514   T 523  â˜’ 150 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 91+574  T 665  â˜’ 703 \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 42+487  T 529  â˜’ 488 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 469+275 T 744  â˜’ 710 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 495+10  T 505  â˜’ 550 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3380 - accuracy: 0.5004 - val_loss: 1.1472 - val_accuracy: 0.5654\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "Q 74+679  T 753  â˜’ 739 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 531+0   T 531  â˜’ 544 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 394+227 T 621  â˜’ 629 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 39+466  T 505  â˜’ 409 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 53+88   T 141  â˜’ 139 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 253+690 T 943  â˜’ 900 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 7+95    T 102  â˜’ 10  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 805+100 T 905  â˜’ 965 \n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Q 49+218  T 267  â˜’ 265 \n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Q 408+0   T 408  â˜’ 410 \n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0207 - accuracy: 0.6243 - val_loss: 0.9086 - val_accuracy: 0.6712\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 18+6    T 24   â˜’ 21  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 237+69  T 306  â˜’ 309 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 1+242   T 243  â˜’ 247 \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 42+31   T 73   â˜’ 78  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 406+22  T 428  â˜’ 426 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 450+92  T 542  â˜’ 546 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 637+46  T 683  â˜’ 689 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 513+332 T 845  â˜’ 944 \n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Q 354+347 T 701  â˜‘ 701 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 2+81    T 83   â˜’ 89  \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8484 - accuracy: 0.6898 - val_loss: 0.8073 - val_accuracy: 0.7016\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 161+809 T 970  â˜’ 961 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 757+656 T 1413 â˜‘ 1413\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 82+479  T 561  â˜‘ 561 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 70+82   T 152  â˜’ 140 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 816+19  T 835  â˜’ 833 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 342+35  T 377  â˜’ 376 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 440+32  T 472  â˜’ 476 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 977+14  T 991  â˜’ 990 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 69+298  T 367  â˜’ 361 \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 27+907  T 934  â˜’ 930 \n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7486 - accuracy: 0.7285 - val_loss: 0.6987 - val_accuracy: 0.7488\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 905+624 T 1529 â˜’ 1540\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 27+716  T 743  â˜’ 740 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 208+761 T 969  â˜’ 960 \n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Q 944+633 T 1577 â˜‘ 1577\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 945+225 T 1170 â˜’ 1179\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 19+100  T 119  â˜’ 111 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 273+217 T 490  â˜’ 494 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 64+86   T 150  â˜’ 154 \n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Q 18+61   T 79   â˜’ 74  \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 8+519   T 527  â˜’ 525 \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.6312 - accuracy: 0.7725 - val_loss: 0.5258 - val_accuracy: 0.8100\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 83+839  T 922  â˜’ 915 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 592+12  T 604  â˜’ 605 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 998+20  T 1018 â˜’ 1019\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 69+764  T 833  â˜’ 832 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 68+378  T 446  â˜’ 445 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 726+342 T 1068 â˜’ 1078\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 83+895  T 978  â˜’ 971 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 75+79   T 154  â˜’ 153 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 28+1    T 29   â˜’ 39  \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 941+4   T 945  â˜’ 944 \n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.4005 - accuracy: 0.8649 - val_loss: 0.2863 - val_accuracy: 0.9211\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Q 13+792  T 805  â˜’ 705 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 1+337   T 338  â˜‘ 338 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 12+620  T 632  â˜‘ 632 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 252+18  T 270  â˜‘ 270 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 156+46  T 202  â˜‘ 202 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 771+496 T 1267 â˜’ 1276\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 3+239   T 242  â˜‘ 242 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 13+926  T 939  â˜’ 938 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 534+14  T 548  â˜‘ 548 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 84+962  T 1046 â˜’ 1045\n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2313 - accuracy: 0.9391 - val_loss: 0.1675 - val_accuracy: 0.9639\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 734+170 T 904  â˜’ 905 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 610+36  T 646  â˜‘ 646 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 1+910   T 911  â˜‘ 911 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 655+3   T 658  â˜‘ 658 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 184+59  T 243  â˜‘ 243 \n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Q 886+10  T 896  â˜‘ 896 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 623+998 T 1621 â˜’ 1620\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 438+0   T 438  â˜‘ 438 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 44+56   T 100  â˜‘ 100 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 6+994   T 1000 â˜‘ 1000\n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.1504 - accuracy: 0.9630 - val_loss: 0.1118 - val_accuracy: 0.9739\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 397+809 T 1206 â˜‘ 1206\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 367+905 T 1272 â˜‘ 1272\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 17+92   T 109  â˜‘ 109 \n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Q 7+447   T 454  â˜‘ 454 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 434+0   T 434  â˜‘ 434 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 6+978   T 984  â˜‘ 984 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 319+57  T 376  â˜‘ 376 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 1+40    T 41   â˜’ 42  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 324+1   T 325  â˜‘ 325 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 738+49  T 787  â˜‘ 787 \n",
      "\n",
      "Iteration 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0960 - accuracy: 0.9782 - val_loss: 0.1268 - val_accuracy: 0.9643\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 38+808  T 846  â˜‘ 846 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 826+71  T 897  â˜‘ 897 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 603+0   T 603  â˜‘ 603 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 66+831  T 897  â˜‘ 897 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 897+506 T 1403 â˜‘ 1403\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 977+132 T 1109 â˜‘ 1109\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 425+90  T 515  â˜‘ 515 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 40+616  T 656  â˜‘ 656 \n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Q 307+717 T 1024 â˜’ 1034\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 81+727  T 808  â˜‘ 808 \n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0708 - accuracy: 0.9835 - val_loss: 0.0794 - val_accuracy: 0.9776\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 16+280  T 296  â˜‘ 296 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 97+745  T 842  â˜‘ 842 \n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Q 396+951 T 1347 â˜‘ 1347\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 184+90  T 274  â˜‘ 274 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 88+85   T 173  â˜‘ 173 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 253+293 T 546  â˜‘ 546 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 46+636  T 682  â˜‘ 682 \n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Q 462+433 T 895  â˜‘ 895 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 820+13  T 833  â˜‘ 833 \n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Q 65+864  T 929  â˜‘ 929 \n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0638 - accuracy: 0.9837 - val_loss: 0.0546 - val_accuracy: 0.9868\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 716+854 T 1570 â˜‘ 1570\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 262+98  T 360  â˜‘ 360 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 572+60  T 632  â˜‘ 632 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 162+928 T 1090 â˜‘ 1090\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 289+463 T 752  â˜‘ 752 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 202+19  T 221  â˜‘ 221 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 404+42  T 446  â˜‘ 446 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 661+1   T 662  â˜‘ 662 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 344+41  T 385  â˜‘ 385 \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 29+31   T 60   â˜‘ 60  \n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0477 - accuracy: 0.9879 - val_loss: 0.0333 - val_accuracy: 0.9933\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 969+266 T 1235 â˜‘ 1235\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 10+999  T 1009 â˜’ 1019\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 6+358   T 364  â˜‘ 364 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 453+86  T 539  â˜‘ 539 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 53+82   T 135  â˜‘ 135 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 27+754  T 781  â˜‘ 781 \n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Q 73+703  T 776  â˜‘ 776 \n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 74+0    T 74   â˜‘ 74  \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 743+742 T 1485 â˜‘ 1485\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 40+746  T 786  â˜‘ 786 \n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0421 - accuracy: 0.9890 - val_loss: 0.0394 - val_accuracy: 0.9900\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 12+287  T 299  â˜’ 209 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 4+316   T 320  â˜‘ 320 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 475+3   T 478  â˜‘ 478 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 7+872   T 879  â˜‘ 879 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 98+596  T 694  â˜‘ 694 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 389+31  T 420  â˜‘ 420 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 46+407  T 453  â˜‘ 453 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 545+28  T 573  â˜‘ 573 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 219+504 T 723  â˜‘ 723 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 455+36  T 491  â˜‘ 491 \n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0358 - accuracy: 0.9907 - val_loss: 0.0844 - val_accuracy: 0.9701\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 87+188  T 275  â˜‘ 275 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 7+580   T 587  â˜‘ 587 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 337+32  T 369  â˜‘ 369 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 31+14   T 45   â˜‘ 45  \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 44+43   T 87   â˜‘ 87  \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 729+941 T 1670 â˜‘ 1670\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 335+129 T 464  â˜‘ 464 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 301+82  T 383  â˜‘ 383 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 59+612  T 671  â˜‘ 671 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 743+742 T 1485 â˜‘ 1485\n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 0.1094 - val_accuracy: 0.9620\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 531+39  T 570  â˜‘ 570 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 182+6   T 188  â˜‘ 188 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 224+58  T 282  â˜‘ 282 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 74+193  T 267  â˜‘ 267 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 7+263   T 270  â˜‘ 270 \n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Q 438+161 T 599  â˜‘ 599 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 593+33  T 626  â˜‘ 626 \n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Q 860+7   T 867  â˜‘ 867 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 565+93  T 658  â˜‘ 658 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 288+5   T 293  â˜‘ 293 \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0406 - accuracy: 0.9891 - val_loss: 0.0174 - val_accuracy: 0.9969\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 12+842  T 854  â˜‘ 854 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 900+543 T 1443 â˜‘ 1443\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 645+517 T 1162 â˜‘ 1162\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 779+576 T 1355 â˜‘ 1355\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Q 81+203  T 284  â˜‘ 284 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 81+398  T 479  â˜‘ 479 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 8+377   T 385  â˜‘ 385 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 46+407  T 453  â˜‘ 453 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 900+56  T 956  â˜‘ 956 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 936+60  T 996  â˜‘ 996 \n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.1659 - val_accuracy: 0.9455\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 93+124  T 217  â˜‘ 217 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 45+154  T 199  â˜‘ 199 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 247+85  T 332  â˜‘ 332 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 35+52   T 87   â˜‘ 87  \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 132+66  T 198  â˜‘ 198 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 664+46  T 710  â˜‘ 710 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 339+424 T 763  â˜‘ 763 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 45+496  T 541  â˜‘ 541 \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 977+991 T 1968 â˜’ 1858\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Q 27+430  T 457  â˜‘ 457 \n",
      "\n",
      "Iteration 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0238 - accuracy: 0.9942 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 6+835   T 841  â˜‘ 841 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 5+475   T 480  â˜‘ 480 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 118+428 T 546  â˜‘ 546 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 713+245 T 958  â˜‘ 958 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 685+433 T 1118 â˜‘ 1118\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 210+730 T 940  â˜‘ 940 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 513+59  T 572  â˜‘ 572 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 18+20   T 38   â˜‘ 38  \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 134+894 T 1028 â˜‘ 1028\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 4+917   T 921  â˜‘ 921 \n",
      "\n",
      "Iteration 20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0337 - accuracy: 0.9904 - val_loss: 0.0230 - val_accuracy: 0.9934\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 862+3   T 865  â˜‘ 865 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 908+0   T 908  â˜‘ 908 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 1+919   T 920  â˜‘ 920 \n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Q 98+432  T 530  â˜‘ 530 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 937+17  T 954  â˜‘ 954 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 2+200   T 202  â˜‘ 202 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 53+823  T 876  â˜‘ 876 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 373+94  T 467  â˜‘ 467 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 531+70  T 601  â˜‘ 601 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 20+948  T 968  â˜‘ 968 \n",
      "\n",
      "Iteration 21\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 0.0305 - val_accuracy: 0.9901\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Q 34+80   T 114  â˜‘ 114 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 23+300  T 323  â˜‘ 323 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 662+59  T 721  â˜‘ 721 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 89+851  T 940  â˜‘ 940 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 35+593  T 628  â˜‘ 628 \n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "Q 377+77  T 454  â˜‘ 454 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 8+112   T 120  â˜‘ 120 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 894+2   T 896  â˜‘ 896 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 99+42   T 141  â˜‘ 141 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 462+643 T 1105 â˜‘ 1105\n",
      "\n",
      "Iteration 22\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0182 - val_accuracy: 0.9953\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 83+839  T 922  â˜‘ 922 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 87+97   T 184  â˜‘ 184 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 541+82  T 623  â˜‘ 623 \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 191+272 T 463  â˜‘ 463 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 5+469   T 474  â˜‘ 474 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 3+541   T 544  â˜‘ 544 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 858+91  T 949  â˜‘ 949 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 8+353   T 361  â˜‘ 361 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 13+71   T 84   â˜‘ 84  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 334+228 T 562  â˜‘ 562 \n",
      "\n",
      "Iteration 23\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 713+716 T 1429 â˜‘ 1429\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 814+57  T 871  â˜‘ 871 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 724+33  T 757  â˜‘ 757 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 6+498   T 504  â˜‘ 504 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 964+69  T 1033 â˜‘ 1033\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 312+86  T 398  â˜‘ 398 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 89+419  T 508  â˜‘ 508 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 918+11  T 929  â˜‘ 929 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 332+89  T 421  â˜‘ 421 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 296+857 T 1153 â˜‘ 1153\n",
      "\n",
      "Iteration 24\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0052 - val_accuracy: 0.9994\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 848+356 T 1204 â˜‘ 1204\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 41+432  T 473  â˜‘ 473 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 39+756  T 795  â˜‘ 795 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 4+322   T 326  â˜‘ 326 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 98+10   T 108  â˜‘ 108 \n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Q 308+604 T 912  â˜‘ 912 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 42+849  T 891  â˜‘ 891 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 402+64  T 466  â˜‘ 466 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 286+66  T 352  â˜‘ 352 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 493+40  T 533  â˜‘ 533 \n",
      "\n",
      "Iteration 25\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0449 - val_accuracy: 0.9861\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 64+437  T 501  â˜‘ 501 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 5+444   T 449  â˜‘ 449 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 764+918 T 1682 â˜‘ 1682\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 3+822   T 825  â˜‘ 825 \n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Q 422+94  T 516  â˜‘ 516 \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 389+1   T 390  â˜‘ 390 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 40+838  T 878  â˜‘ 878 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 439+728 T 1167 â˜‘ 1167\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 71+970  T 1041 â˜‘ 1041\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 914+810 T 1724 â˜’ 1734\n",
      "\n",
      "Iteration 26\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.1525 - val_accuracy: 0.9704\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 415+618 T 1033 â˜’ 933 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 254+69  T 323  â˜‘ 323 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 977+14  T 991  â˜‘ 991 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 814+599 T 1413 â˜‘ 1413\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 515+747 T 1262 â˜’ 1162\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 311+62  T 373  â˜‘ 373 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 643+24  T 667  â˜‘ 667 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 422+94  T 516  â˜‘ 516 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 931+865 T 1796 â˜‘ 1796\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 20+163  T 183  â˜‘ 183 \n",
      "\n",
      "Iteration 27\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0135 - accuracy: 0.9967 - val_loss: 0.0033 - val_accuracy: 0.9998\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 530+99  T 629  â˜‘ 629 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 815+80  T 895  â˜‘ 895 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 10+944  T 954  â˜‘ 954 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 477+38  T 515  â˜‘ 515 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 829+820 T 1649 â˜‘ 1649\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 83+996  T 1079 â˜‘ 1079\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 26+758  T 784  â˜‘ 784 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 52+934  T 986  â˜‘ 986 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 55+983  T 1038 â˜‘ 1038\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 348+85  T 433  â˜‘ 433 \n",
      "\n",
      "Iteration 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.0116 - val_accuracy: 0.9976\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 688+19  T 707  â˜‘ 707 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 673+65  T 738  â˜‘ 738 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 30+71   T 101  â˜‘ 101 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 53+390  T 443  â˜‘ 443 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 475+185 T 660  â˜‘ 660 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 348+716 T 1064 â˜‘ 1064\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 172+14  T 186  â˜‘ 186 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 55+674  T 729  â˜‘ 729 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 31+460  T 491  â˜‘ 491 \n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Q 59+400  T 459  â˜‘ 459 \n",
      "\n",
      "Iteration 29\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0035 - val_accuracy: 0.9997\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 680+182 T 862  â˜‘ 862 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 508+742 T 1250 â˜‘ 1250\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 21+333  T 354  â˜‘ 354 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 41+63   T 104  â˜‘ 104 \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 4+732   T 736  â˜‘ 736 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 191+5   T 196  â˜‘ 196 \n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Q 86+305  T 391  â˜‘ 391 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 8+809   T 817  â˜‘ 817 \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 4+646   T 650  â˜‘ 650 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 721+70  T 791  â˜‘ 791 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"â˜‘ \" + guess)\n",
    "        else:\n",
    "            print(\"â˜’ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63KkNSz56zVS"
   },
   "source": [
    "You'll get to 99+% validation accuracy after ~30 epochs.\n",
    "\n",
    "Example available on HuggingFace.\n",
    "\n",
    "| Trained Model | Demo |\n",
    "| :--: | :--: |\n",
    "| [![Generic badge](https://img.shields.io/badge/ðŸ¤—%20Model-Addition%20LSTM-black.svg)](https://huggingface.co/keras-io/addition-lstm) | [![Generic badge](https://img.shields.io/badge/ðŸ¤—%20Spaces-Addition%20LSTM-black.svg)](https://huggingface.co/spaces/keras-io/addition-lstm) |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "addition_rnn",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
